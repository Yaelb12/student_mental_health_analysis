{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fc640f",
   "metadata": {},
   "source": [
    "### Student Mental Health Analysis - Final Project\n",
    "Authors: Eden Elkoubi, Yael Barbash, Avigail Cohen\n",
    "\n",
    "Dataset: Student Mental Health Survey\n",
    "Project Overview & Kick-off\n",
    "This project investigates the relationship between academic disciplines (STEM vs. Non-STEM), social support, and mental health outcomes among students.\n",
    "\n",
    "Research Questions\n",
    "1.Is there a significant difference in anxiety and stress levels between STEM and Humanities/Social Science students?    \n",
    "2.Does social support act as a moderator in the relationship between academic stress and mental health?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c426c",
   "metadata": {},
   "source": [
    "#####Step 1: Data Preprocessing and Cleaning\n",
    "\n",
    "Handling missing values\n",
    "Missing values were identified and treated in key variables. Rows with missing values in Substance_Use were removed, as this categorical variable cannot be meaningfully imputed. Missing values in CGPA, a continuous variable, were replaced with the mean CGPA calculated from the available (non-missing) data.\n",
    "\n",
    "Feature engineering\n",
    "A new binary variable named Is_STEM was created to represent whether a student belongs to a STEM-related field. The variable was coded as 1 for students in Engineering, Medical, or Computer Science programs, and 0 for all other fields of study.\n",
    "\n",
    "Categorical data transformation\n",
    "Categorical variables were converted into numerical form to enable statistical analysis. Specifically, Social Support was encoded as low = 1, moderate = 2, and high = 3, while Sleep Quality was encoded as poor = 1, average = 2, and good = 3.\n",
    "\n",
    "Outlier detection and treatment\n",
    "Outliers in selected numerical variables were addressed using the Interquartile Range (IQR) method. Values outside 1.5 times the IQR were capped at the lower and upper bounds, reducing the impact of extreme values while preserving all observations.\n",
    "\n",
    "Final dataset preparation\n",
    "After completing the preprocessing steps, the cleaned and transformed dataset was saved and used for subsequent statistical analyses and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf8da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#level 1\n",
    "df = pd.read_csv(\"st_1.csv\") # Load the dataset\n",
    "cgpa_mean = df[\"CGPA\"].mean(skipna=True) # Calculate the mean CGPA (excluding missing values)\n",
    "df_clean = df.dropna(subset=[\"Substance_Use\"]).copy() # Remove rows with missing values in Substance_Use\n",
    "df_clean[\"CGPA\"] = df_clean[\"CGPA\"].fillna(cgpa_mean) # Fill missing CGPA values with the calculated mean\n",
    "df_clean.to_csv(\"st_1_cleaned.csv\", index=False) # Save the cleaned dataset\n",
    "\n",
    "\n",
    "#level 2- Feature Engineering: Create a binary variable 'Is_STEM'\n",
    "# Assign 1 for Engineering, Medical, and Computer Science; 0 for all others\n",
    "stem_courses = ['Engineering', 'Medical', 'Computer Science']\n",
    "df_clean['Is_STEM'] = df_clean['Course'].isin(stem_courses).astype(int)\n",
    "\n",
    "# level 3- Data Transformation: Convert categorical variables to numerical values\n",
    "# Define mapping: Poor/Low = 1, Average/Moderate = 2, Good/High = 3\n",
    "sleep_mapping = {'Poor': 1, 'Average': 2, 'Good': 3}\n",
    "support_mapping = {'Low': 1, 'Moderate': 2, 'High': 3}\n",
    "\n",
    "# Apply the mapping to the respective columns\n",
    "df_clean['Sleep_Quality'] = df_clean['Sleep_Quality'].map(sleep_mapping)\n",
    "df_clean['Social_Support'] = df_clean['Social_Support'].map(support_mapping)\n",
    "\n",
    "\n",
    "# level 4a- Handling Outliers using IQR for continuous variables\n",
    "# This will remove extreme/unrealistic values for Age, CGPA, and Credit Load\n",
    "outlier_columns = ['Age', 'CGPA', 'Semester_Credit_Load']\n",
    "\n",
    "for col in outlier_columns:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Filter the data to keep only values within the calculated bounds\n",
    "    df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "\n",
    "\n",
    "# level 4b- Logical Range Validation for score columns\n",
    "# Ensure that scores like Stress, Depression, and Anxiety are within the valid range [0, 5]\n",
    "score_columns = ['Stress_Level', 'Depression_Score', 'Anxiety_Score', 'Financial_Stress']\n",
    "\n",
    "for col in score_columns:\n",
    "    # Filter out any values that are negative or greater than 5\n",
    "    df_clean = df_clean[(df_clean[col] >= 0) & (df_clean[col] <= 5)]\n",
    "\n",
    "# Optional: Save the final cleaned dataset\n",
    "df_clean.to_csv(\"st_1_cleaned_final.csv\", index=False)\n",
    "\n",
    "# Save the final cleaned dataset as st1.csv\n",
    "df_clean.to_csv(\"st_1.csv\", index=False)\n",
    "\n",
    "# Save the final cleaned dataset as st1.csv\n",
    "df_clean.to_csv(\"st_1.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47b4728",
   "metadata": {},
   "source": [
    "3.EDEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3712fdd4",
   "metadata": {},
   "source": [
    "### Setup and Logging \n",
    " According to the project guidelines, we must use a logger instead of print statements to track the execution flow. This part sets up the professional logging configuration that will record all statistical results into a file named analysis_log.log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8175f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Configure the logger to track the analysis process\n",
    "def setup_logger():\n",
    "    \"\"\"\n",
    "    Sets up a logger that outputs to both a log file and the console.\n",
    "    This replaces standard 'print' statements as per project requirements.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(\"analysis_log.log\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "   \n",
    "logger = setup_logger()\n",
    "logger.info(\"Logger initialized. Ready for statistical analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb7b67",
   "metadata": {},
   "source": [
    "### Hypothesis Testing - Independent T-Test\n",
    "Explanation: The first hypothesis explores whether there is a significant difference in mental health scores between STEM students and students from other faculties. We use an Independent T-test, ensuring we handle missing values (NaN) correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a169448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_group_comparison(df, group_col, target_col):\n",
    "    \"\"\"\n",
    "    Hypothesis: Mental health levels differ between STEM and Non-STEM students.\n",
    "    Method: Independent Two-Sample T-Test.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Comparing {target_col} between groups in {group_col}\")\n",
    "\n",
    "    # Separating groups based on the binary indicator (1 for STEM, 0 for others)\n",
    "    # Using meaningful variable names instead of raw indices\n",
    "    stem_group = df[df[group_col] == 1][target_col]\n",
    "    non_stem_group = df[df[group_col] == 0][target_col]\n",
    "\n",
    "    # Performing the T-test\n",
    "    t_stat, p_val = stats.ttest_ind(stem_group, non_stem_group, nan_policy='omit')\n",
    "\n",
    "    logger.info(f\"T-test results - Statistic: {t_stat:.4f}, P-value: {p_val:.4f}\")\n",
    "    \n",
    "    # Interpretation logic\n",
    "    if p_val < 0.05:\n",
    "        logger.info(\"Result is statistically significant (p < 0.05).\")\n",
    "    else:\n",
    "        logger.info(\"Result is not statistically significant (p >= 0.05).\")\n",
    "        \n",
    "    return t_stat, p_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f25a8a",
   "metadata": {},
   "source": [
    "### Correlation Analysis\n",
    "Explanation: The second hypothesis checks for a linear relationship between academic performance (CGPA) and substance use. We use Pearsonâ€™s Correlation coefficient to determine the strength and direction of this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_variable_correlation(df, var_x, var_y):\n",
    "    \"\"\"\n",
    "    Hypothesis: There is a correlation between Academic Load/CGPA and Substance Use.\n",
    "    Method: Pearson Correlation.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Calculating correlation between {var_x} and {var_y}\")\n",
    "\n",
    "    # Cleaning data locally for this specific test\n",
    "    valid_data = df[[var_x, var_y]].dropna()\n",
    "    \n",
    "    correlation_coeff, p_value = stats.pearsonr(valid_data[var_x], valid_data[var_y])\n",
    "\n",
    "    logger.info(f\"Correlation results - Coefficient: {correlation_coeff:.4f}, P-value: {p_value:.4f}\")\n",
    "    return correlation_coeff, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab2438c",
   "metadata": {},
   "source": [
    "### Moderation Analysis (Regression)\n",
    "Explanation: To increase the \"Complexity Level\" (as required in the grading rubric), we implement a moderation model. We test if \"Social Support\" moderates the relationship between \"Academic Load\" and \"Mental Health Stress\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_moderation_model(df, outcome, predictor, moderator):\n",
    "    \"\"\"\n",
    "    Hypothesis: Social Support acts as a moderator for the effect of Academic Load on Stress.\n",
    "    Method: OLS Regression with an interaction term.\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting Moderation Analysis (Regression with interaction term)\")\n",
    "\n",
    "    # Creating the interaction term (Predictor * Moderator)\n",
    "    df_temp = df.copy()\n",
    "    df_temp['interaction'] = df_temp[predictor] * df_temp[moderator]\n",
    "\n",
    "    # Independent variables: Predictor, Moderator, and their Interaction\n",
    "    X = df_temp[[predictor, moderator, 'interaction']]\n",
    "    X = sm.add_constant(X)  # Adds the intercept (constant) to the model\n",
    "    y = df_temp[outcome]\n",
    "\n",
    "    # Fit the OLS model\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    logger.info(\"Moderation model fitting complete.\")\n",
    "    # We return the summary which contains all statistical details\n",
    "    return model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa05b1a6",
   "metadata": {},
   "source": [
    "### Main Execution Block\n",
    "Explanation: This is the entry point of the script. Following the guidelines, the main() function is kept minimal, serving only to orchestrate the flow of the analysis modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2eccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution flow. In a real scenario, 'df' comes from the Preprocessing module.\n",
    "    \"\"\"\n",
    "    logger.info(\"Final Project - Part II: Statistical Analysis Phase Started\")\n",
    "\n",
    "    # Placeholder: In your project, replace this with your actual cleaned DataFrame\n",
    "    # df = pd.read_csv(\"your_cleaned_data.csv\")\n",
    "\n",
    "    # Example calls for testing the logic:\n",
    "    # perform_group_comparison(df, 'Is_STEM', 'Stress_Score')\n",
    "    # analyze_variable_correlation(df, 'CGPA', 'Substance_Use')\n",
    "    # regression_results = run_moderation_model(df, 'Stress_Score', 'Academic_Load', 'Social_Support')\n",
    "    \n",
    "    logger.info(\"Statistical Analysis Phase Completed Successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
