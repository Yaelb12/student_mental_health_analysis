{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14fc640f",
   "metadata": {},
   "source": [
    "### Student Mental Health Analysis - Final Project\n",
    "Authors: Eden Elkoubi, Yael Barbash, Avigail Cohen\n",
    "\n",
    "Dataset: Student Mental Health Survey\n",
    "Project Overview & Kick-off\n",
    "This project investigates the relationship between academic disciplines (STEM vs. Non-STEM), social support, and mental health outcomes among students.\n",
    "\n",
    "Research Questions\n",
    "1.Is there a significant difference in anxiety and stress levels between STEM and Humanities/Social Science students?    \n",
    "2.Does social support act as a moderator in the relationship between academic stress and mental health?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc640f",
   "metadata": {},
   "source": [
    "### Student Mental Health Analysis - Final Project\n",
    "Authors: Eden Elkoubi, Yael Barbash, Avigail Cohen\n",
    "\n",
    "Dataset: Student Mental Health Survey\n",
    "Project Overview & Kick-off\n",
    "This project investigates the relationship between academic disciplines (STEM vs. Non-STEM), social support, and mental health outcomes among students.\n",
    "\n",
    "Research Questions\n",
    "1.Is there a significant difference in anxiety and stress levels between STEM and Humanities/Social Science students?    \n",
    "2.Does social support act as a moderator in the relationship between academic stress and mental health?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0e0d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85c426c",
   "metadata": {},
   "source": [
    "#####Step 1: Data Preprocessing and Cleaning\n",
    "\n",
    "Handling missing values\n",
    "Missing values were identified and treated in key variables. Rows with missing values in Substance_Use were removed, as this categorical variable cannot be meaningfully imputed. Missing values in CGPA, a continuous variable, were replaced with the mean CGPA calculated from the available (non-missing) data.\n",
    "\n",
    "Feature engineering\n",
    "A new binary variable named Is_STEM was created to represent whether a student belongs to a STEM-related field. The variable was coded as 1 for students in Engineering, Medical, or Computer Science programs, and 0 for all other fields of study.\n",
    "\n",
    "Categorical data transformation\n",
    "Categorical variables were converted into numerical form to enable statistical analysis. Specifically, Social Support was encoded as low = 1, moderate = 2, and high = 3, while Sleep Quality was encoded as poor = 1, average = 2, and good = 3.\n",
    "\n",
    "Outlier detection and treatment\n",
    "Outliers in selected numerical variables were addressed using the Interquartile Range (IQR) method. Values outside 1.5 times the IQR were capped at the lower and upper bounds, reducing the impact of extreme values while preserving all observations.\n",
    "\n",
    "Final dataset preparation\n",
    "After completing the preprocessing steps, the cleaned and transformed dataset was saved and used for subsequent statistical analyses and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf8da1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_2508\\3802332.py:22: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean['Sleep_Quality'] = df_clean['Sleep_Quality'].replace(sleep_mapping)\n",
      "C:\\Users\\cohen\\AppData\\Local\\Temp\\ipykernel_2508\\3802332.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean['Social_Support'] = df_clean['Social_Support'].replace(support_mapping)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#level 1\n",
    "df = pd.read_csv(\"st_1.csv\") # Load the dataset\n",
    "cgpa_mean = df[\"CGPA\"].mean(skipna=True) # Calculate the mean CGPA (excluding missing values)\n",
    "df_clean = df.dropna(subset=[\"Substance_Use\"]).copy() # Remove rows with missing values in Substance_Use\n",
    "df_clean[\"CGPA\"] = df_clean[\"CGPA\"].fillna(cgpa_mean) # Fill missing CGPA values with the calculated mean\n",
    "#df_clean.to_csv(\"st_1_cleaned.csv\", index=False) # Save the cleaned dataset\n",
    "\n",
    "\n",
    "#level 2- Feature Engineering: Create a binary variable 'Is_STEM'\n",
    "# Assign 1 for Engineering, Medical, and Computer Science; 0 for all others\n",
    "stem_courses = ['Engineering', 'Medical', 'Computer Science']\n",
    "df_clean['Is_STEM'] = df_clean['Course'].isin(stem_courses).astype(int)\n",
    "\n",
    "# level 3- Data Transformation: Convert categorical variables to numerical values\n",
    "# Define mapping: Poor/Low = 1, Average/Moderate = 2, Good/High = 3\n",
    "sleep_mapping = {'Poor': 1, 'Average': 2, 'Good': 3}\n",
    "support_mapping = {'Low': 1, 'Moderate': 2, 'High': 3}\n",
    "\n",
    "# Apply the mapping to the respective columns\n",
    "df_clean['Sleep_Quality'] = df_clean['Sleep_Quality'].replace(sleep_mapping)\n",
    "df_clean['Social_Support'] = df_clean['Social_Support'].replace(support_mapping)\n",
    "\n",
    "\n",
    "# level 4a- Handling Outliers using IQR for continuous variables\n",
    "# This will remove extreme/unrealistic values for Age, CGPA, and Credit Load\n",
    "outlier_columns = ['Age', 'CGPA', 'Semester_Credit_Load']\n",
    "\n",
    "for col in outlier_columns:\n",
    "    Q1 = df_clean[col].quantile(0.25)\n",
    "    Q3 = df_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Filter the data to keep only values within the calculated bounds\n",
    "    df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "\n",
    "\n",
    "# level 4b- Logical Range Validation for score columns\n",
    "# Ensure that scores like Stress, Depression, and Anxiety are within the valid range [0, 5]\n",
    "score_columns = ['Stress_Level', 'Depression_Score', 'Anxiety_Score', 'Financial_Stress']\n",
    "\n",
    "for col in score_columns:\n",
    "    # Filter out any values that are negative or greater than 5\n",
    "    df_clean = df_clean[(df_clean[col] >= 0) & (df_clean[col] <= 5)]\n",
    "\n",
    "# Save the final cleaned dataset as st1.csv\n",
    "df_clean.to_csv(\"clean_data.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47b4728",
   "metadata": {},
   "source": [
    "3.EDEN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3712fdd4",
   "metadata": {},
   "source": [
    "### Setup and Logging \n",
    " According to the project guidelines, we must use a logger instead of print statements to track the execution flow. This part sets up the professional logging configuration that will record all statistical results into a file named analysis_log.log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8175f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
<<<<<<< HEAD
    "##\n",
=======
    "\n",
>>>>>>> 182d03eaca5c452cf39476180a0d06d64cdd071f
    "# Configure the logger to track the analysis process\n",
    "def setup_logger():\n",
    "    \"\"\"\n",
    "    Sets up a logger that outputs to both a log file and the console.\n",
    "    This replaces standard 'print' statements as per project requirements.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(\"analysis_log.log\"),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    return logging.getLogger(__name__)\n",
    "   \n",
    "logger = setup_logger()\n",
    "logger.info(\"Logger initialized. Ready for statistical analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb7b67",
   "metadata": {},
   "source": [
    "### Hypothesis Testing - Independent T-Test\n",
    "Explanation: The first hypothesis explores whether there is a significant difference in mental health scores between STEM students and students from other faculties. We use an Independent T-test, ensuring we handle missing values (NaN) correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a169448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_group_comparison(df, group_col, target_col):\n",
    "    \"\"\"\n",
<<<<<<< HEAD
    "    Hypothesis:\n",
    "    Mental health levels differ between STEM and Non-STEM students.\n",
    "\n",
    "    Method:\n",
    "    Mann–Whitney U test (non-parametric), suitable for ordinal data (0–5)\n",
    "    and non-normal distributions.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Comparing {target_col} between groups in {group_col}\")\n",
    "\n",
    "    # Separate groups\n",
    "    stem_group = df[df[group_col] == 1][target_col].dropna()\n",
    "    non_stem_group = df[df[group_col] == 0][target_col].dropna()\n",
    "\n",
    "    # Mann–Whitney U Test\n",
    "    u_stat, p_val = stats.mannwhitneyu(\n",
    "        stem_group,\n",
    "        non_stem_group,\n",
    "        alternative='two-sided'\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Mann–Whitney U results - U statistic: {u_stat:.4f}, P-value: {p_val:.4f}\")\n",
    "\n",
    "    # Interpretation\n",
=======
    "    Hypothesis: Mental health levels differ between STEM and Non-STEM students.\n",
    "    Method: Independent Two-Sample T-Test.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Comparing {target_col} between groups in {group_col}\")\n",
    "\n",
    "    # Separating groups based on the binary indicator (1 for STEM, 0 for others)\n",
    "    # Using meaningful variable names instead of raw indices\n",
    "    stem_group = df[df[group_col] == 1][target_col]\n",
    "    non_stem_group = df[df[group_col] == 0][target_col]\n",
    "\n",
    "    # Performing the T-test\n",
    "    t_stat, p_val = stats.ttest_ind(stem_group, non_stem_group, nan_policy='omit')\n",
    "\n",
    "    logger.info(f\"T-test results - Statistic: {t_stat:.4f}, P-value: {p_val:.4f}\")\n",
    "    \n",
    "    # Interpretation logic\n",
>>>>>>> 182d03eaca5c452cf39476180a0d06d64cdd071f
    "    if p_val < 0.05:\n",
    "        logger.info(\"Result is statistically significant (p < 0.05).\")\n",
    "    else:\n",
    "        logger.info(\"Result is not statistically significant (p >= 0.05).\")\n",
<<<<<<< HEAD
    "\n",
    "    return u_stat, p_val\n"
=======
    "        \n",
    "    return t_stat, p_val"
>>>>>>> 182d03eaca5c452cf39476180a0d06d64cdd071f
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f25a8a",
   "metadata": {},
   "source": [
    "### Correlation Analysis\n",
    "Explanation: The second hypothesis checks for a linear relationship between academic performance (CGPA) and substance use. We use Pearson’s Correlation coefficient to determine the strength and direction of this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f6e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_variable_correlation(df, var_x, var_y):\n",
    "    \"\"\"\n",
<<<<<<< HEAD
    "    Hypothesis:\n",
    "    There is an association between academic factors (e.g., CGPA or credit load)\n",
    "    and substance use behavior.\n",
    "\n",
    "    Method:\n",
    "    Spearman rank-order correlation, suitable for ordinal and non-normally\n",
    "    distributed variables.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Calculating correlation between {var_x} and {var_y}\")\n",
    "\n",
    "    # Remove missing values\n",
    "    valid_data = df[[var_x, var_y]].dropna()\n",
    "\n",
    "    # Spearman correlation\n",
    "    correlation_coeff, p_value = stats.spearmanr(\n",
    "        valid_data[var_x],\n",
    "        valid_data[var_y]\n",
    "    )\n",
    "\n",
    "    logger.info(\n",
    "        f\"Spearman correlation results - \"\n",
    "        f\"Coefficient: {correlation_coeff:.4f}, P-value: {p_value:.4f}\"\n",
    "    )\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        logger.info(\"Correlation is statistically significant (p < 0.05).\")\n",
    "    else:\n",
    "        logger.info(\"Correlation is not statistically significant (p >= 0.05).\")\n",
    "\n",
    "    return correlation_coeff, p_value\n"
=======
    "    Hypothesis: There is a correlation between Academic Load/CGPA and Substance Use.\n",
    "    Method: Pearson Correlation.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Calculating correlation between {var_x} and {var_y}\")\n",
    "\n",
    "    # Cleaning data locally for this specific test\n",
    "    valid_data = df[[var_x, var_y]].dropna()\n",
    "    \n",
    "    correlation_coeff, p_value = stats.pearsonr(valid_data[var_x], valid_data[var_y])\n",
    "\n",
    "    logger.info(f\"Correlation results - Coefficient: {correlation_coeff:.4f}, P-value: {p_value:.4f}\")\n",
    "    return correlation_coeff, p_value"
>>>>>>> 182d03eaca5c452cf39476180a0d06d64cdd071f
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab2438c",
   "metadata": {},
   "source": [
    "### Moderation Analysis (Regression)\n",
    "Explanation: To increase the \"Complexity Level\" (as required in the grading rubric), we implement a moderation model. We test if \"Social Support\" moderates the relationship between \"Academic Load\" and \"Mental Health Stress\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9d9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_moderation_model(df, outcome, predictor, moderator):\n",
    "    \"\"\"\n",
<<<<<<< HEAD
    "    Hypothesis:\n",
    "    Social support moderates the relationship between academic load\n",
    "    and mental health outcomes.\n",
    "\n",
    "    Method:\n",
    "    OLS regression with centered predictors and an interaction term.\n",
    "    \"\"\"\n",
    "    logger.info(\n",
    "        f\"Starting moderation analysis with outcome={outcome}, \"\n",
    "        f\"predictor={predictor}, moderator={moderator}\"\n",
    "    )\n",
    "\n",
    "    df_temp = df.copy()\n",
    "\n",
    "    # Centering predictor and moderator (important for moderation analysis)\n",
    "    df_temp[f'{predictor}_c'] = df_temp[predictor] - df_temp[predictor].mean()\n",
    "    df_temp[f'{moderator}_c'] = df_temp[moderator] - df_temp[moderator].mean()\n",
    "\n",
    "    # Interaction term\n",
    "    df_temp['interaction'] = (\n",
    "        df_temp[f'{predictor}_c'] * df_temp[f'{moderator}_c']\n",
    "    )\n",
    "\n",
    "    # Design matrix\n",
    "    X = df_temp[[f'{predictor}_c', f'{moderator}_c', 'interaction']]\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    y = df_temp[outcome]\n",
    "\n",
    "    # Fit OLS model\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    logger.info(\"Moderation model fitted successfully.\")\n",
    "    logger.info(f\"R-squared: {model.rsquared:.4f}\")\n",
    "\n",
    "    return model.summary()\n"
=======
    "    Hypothesis: Social Support acts as a moderator for the effect of Academic Load on Stress.\n",
    "    Method: OLS Regression with an interaction term.\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting Moderation Analysis (Regression with interaction term)\")\n",
    "\n",
    "    # Creating the interaction term (Predictor * Moderator)\n",
    "    df_temp = df.copy()\n",
    "    df_temp['interaction'] = df_temp[predictor] * df_temp[moderator]\n",
    "\n",
    "    # Independent variables: Predictor, Moderator, and their Interaction\n",
    "    X = df_temp[[predictor, moderator, 'interaction']]\n",
    "    X = sm.add_constant(X)  # Adds the intercept (constant) to the model\n",
    "    y = df_temp[outcome]\n",
    "\n",
    "    # Fit the OLS model\n",
    "    model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "    logger.info(\"Moderation model fitting complete.\")\n",
    "    # We return the summary which contains all statistical details\n",
    "    return model.summary()"
>>>>>>> 182d03eaca5c452cf39476180a0d06d64cdd071f
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa05b1a6",
   "metadata": {},
   "source": [
    "### Main Execution Block\n",
    "Explanation: This is the entry point of the script. Following the guidelines, the main() function is kept minimal, serving only to orchestrate the flow of the analysis modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2eccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
<<<<<<< HEAD
    "    Main execution flow for the statistical analysis phase.\n",
    "    Assumes that the dataset has undergone basic preprocessing.\n",
    "    \"\"\"\n",
    "    logger.info(\"Final Project – Statistical Analysis Phase Started\")\n",
    "\n",
    "    # Load dataset\n",
    "    try:\n",
    "        df = pd.read_csv(\"st_1.csv\")\n",
    "        logger.info(f\"Dataset loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    except Exception as e:\n",
    "        logger.error(\"Failed to load dataset\", exc_info=True)\n",
    "        return\n",
    "\n",
    " \n",
    "    # Feature Engineering\n",
    "    # Create STEM indicator\n",
    "    stem_fields = ['Engineering', 'Computer Science', 'Medicine', 'Science', 'Technology']\n",
    "    df['Is_STEM'] = df['Course'].apply(lambda x: 1 if x in stem_fields else 0)\n",
    "\n",
    "    # Encode Social Support as ordinal numeric variable\n",
    "    support_map = {'Low': 1, 'Moderate': 2, 'High': 3}\n",
    "    df['Social_Support_Num'] = df['Social_Support'].map(support_map)\n",
    "\n",
    "    logger.info(\"Feature engineering completed.\")\n",
    "\n",
    "\n",
    "    # Group Comparisons\n",
    "    perform_group_comparison(df, 'Is_STEM', 'Stress_Level')\n",
    "    perform_group_comparison(df, 'Is_STEM', 'Anxiety_Score')\n",
    "\n",
    "\n",
    "    # Correlation Analysis\n",
    "    analyze_variable_correlation(df, 'CGPA', 'Substance_Use')\n",
    "\n",
    "\n",
    "    # Moderation Analysis\n",
    "    regression_summary = run_moderation_model(\n",
    "        df,\n",
    "        outcome='Stress_Level',\n",
    "        predictor='Semester_Credit_Load',\n",
    "        moderator='Social_Support_Num'\n",
    "    )\n",
    "\n",
    "    logger.info(\"Moderation analysis completed.\")\n",
    "    logger.info(f\"\\n{regression_summary}\")\n",
    "\n",
    "    logger.info(\"Statistical Analysis Phase Completed Successfully.\")\n"
=======
    "    Main execution flow. In a real scenario, 'df' comes from the Preprocessing module.\n",
    "    \"\"\"\n",
    "    logger.info(\"Final Project - Part II: Statistical Analysis Phase Started\")\n",
    "\n",
    "    # Placeholder: In your project, replace this with your actual cleaned DataFrame\n",
    "    # df = pd.read_csv(\"your_cleaned_data.csv\")\n",
    "\n",
    "    # Example calls for testing the logic:\n",
    "    # perform_group_comparison(df, 'Is_STEM', 'Stress_Score')\n",
    "    # analyze_variable_correlation(df, 'CGPA', 'Substance_Use')\n",
    "    # regression_results = run_moderation_model(df, 'Stress_Score', 'Academic_Load', 'Social_Support')\n",
    "    \n",
    "    logger.info(\"Statistical Analysis Phase Completed Successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
>>>>>>> 182d03eaca5c452cf39476180a0d06d64cdd071f
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
